{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Deep Neural Networks on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '.tmp'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "tf.random.set_seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.reshape(-1, 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_digits(X, y):\n",
    "    return (X[y < 5], y[y < 5]), ((X[y >= 5], y[y >= 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_0, y_train_0), (X_train_5, y_train_5) = split_by_digits(X_train, y_train)\n",
    "(X_test_0, y_test_0), (X_test_5, y_test_5) = split_by_digits(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn on digits 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(n_inputs, n_outputs, params):\n",
    "    model = Sequential()\n",
    "    layer_params = {\n",
    "        'units': 100,\n",
    "        'kernel_initializer': 'he_uniform',\n",
    "        'activation': 'elu'\n",
    "    }\n",
    "    model.add(Dense(input_shape=n_inputs, **layer_params))\n",
    "    for _ in range(4):\n",
    "        model.add(Dense(**layer_params))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(**params),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 119,405\n",
      "Trainable params: 119,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = build_model((28*28,), 5, {})\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filepath=os.path.join(output_dir, 'model-weights.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98093, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.98093 to 0.98599, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98599 to 0.98871, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98871 to 0.99047, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99047\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.99047 to 0.99280, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99280\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.99280 to 0.99319, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99319\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99319\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.99319 to 0.99436, saving model to .tmp\\model-weights.hdf5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99436\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257e6648c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(X_train_0, y_train_0, \n",
    "            epochs=100, \n",
    "            verbose=0, \n",
    "            validation_data=(X_test_0, y_test_0), \n",
    "            callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} 0.9945515\n",
      "{'decay': 1e-10} 0.9943569\n",
      "{'decay': 1e-05, 'lr': 0.001} 0.99513525\n",
      "{'beta_1': 0.89, 'beta_2': 0.99} 0.99532986\n",
      "best accuracy: 0.99532986\n",
      "best_params: {'beta_1': 0.89, 'beta_2': 0.99}\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "if True:\n",
    "    params_grid = [{},\n",
    "                  {'decay': 1e-10},\n",
    "                  {'decay': 1e-5, 'lr': 1e-3},\n",
    "                  {'beta_1': 0.89, 'beta_2': 0.99}]\n",
    "\n",
    "    best_params = None\n",
    "    best_acc = -1\n",
    "    for params in params_grid:\n",
    "        model = build_model((28*28,), 5, params)\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=10, restore_best_weights=True)\n",
    "        model.fit(X_train_0, y_train_0, \n",
    "                  epochs=100, \n",
    "                  verbose=0, \n",
    "                  validation_data=(X_test_0, y_test_0), \n",
    "                  callbacks = [early_stopping])\n",
    "        _, acc = model.evaluate(X_test_0, y_test_0, verbose=0)\n",
    "        print(params, acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_params = params\n",
    "\n",
    "    print('best accuracy:', best_acc)\n",
    "    print('best_params:', params)\n",
    "else:\n",
    "    best_params =  {'beta_1': 0.89, 'beta_2': 0.99}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaning with one normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model_batch_1(n_inputs, n_outputs, n_layers = 4, params = None):\n",
    "    params = {} if params is None else params\n",
    "    model = Sequential()\n",
    "    layer_params = {\n",
    "        'units': 100,\n",
    "        'kernel_initializer': 'he_uniform',\n",
    "        'activation': 'elu'\n",
    "    }\n",
    "    model.add(Dense(input_shape=n_inputs, **layer_params))\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(**layer_params))\n",
    "        if i == n_layers // 2:\n",
    "            model.add(BatchNormalization())\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(**params),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 119,805\n",
      "Trainable params: 119,605\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0_batch_1 = build_model_batch_1((28*28,), 5)\n",
    "model_0_batch_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filepath=os.path.join(output_dir, 'model-weights-batch-1.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98541, saving model to .tmp\\model-weights-batch-1.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.98541\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98541 to 0.99222, saving model to .tmp\\model-weights-batch-1.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.99222\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99222\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99222\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99222\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.99222 to 0.99358, saving model to .tmp\\model-weights-batch-1.hdf5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.99358 to 0.99397, saving model to .tmp\\model-weights-batch-1.hdf5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99397\n",
      "Wall time: 48.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2579f27d710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_0_batch_1.fit(X_train_0, y_train_0, \n",
    "                    epochs=100, \n",
    "                    verbose=0, \n",
    "                    validation_data=(X_test_0, y_test_0), \n",
    "                    callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with 1 normalization layer and 10 inner layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 180,405\n",
      "Trainable params: 180,205\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0_batch_1_10 = build_model_batch_1((28*28,), 5, 10)\n",
    "model_0_batch_1_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filepath=os.path.join(output_dir, 'model-weights-batch-1-10.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96517, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.96517 to 0.98112, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98112 to 0.98541, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98541 to 0.98969, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98969\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98969\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.98969 to 0.99163, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99163\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.99163 to 0.99319, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.99319 to 0.99358, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99358\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99358\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99358\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99358\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.99358 to 0.99397, saving model to .tmp\\model-weights-batch-1-10.hdf5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.99397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257a0caada0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_batch_1_10.fit(X_train_0, y_train_0, \n",
    "                       epochs=100, \n",
    "                       verbose=0, \n",
    "                       validation_data=(X_test_0, y_test_0), \n",
    "                       callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning with 4 inner layers and 4 normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_batch_n(n_inputs, n_outputs, n_layers = 4, params = None):\n",
    "    params = {} if params is None else params\n",
    "    model = Sequential()\n",
    "    layer_params = {\n",
    "        'units': 100,\n",
    "        'kernel_initializer': 'he_uniform',\n",
    "        'activation': 'elu'\n",
    "    }\n",
    "    model.add(Dense(input_shape=n_inputs, **layer_params))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dense(**layer_params))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(**params),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_4 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_5 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 121,005\n",
      "Trainable params: 120,205\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0_batch_n_4 = build_model_batch_n((28*28,), 5)\n",
    "model_0_batch_n_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=os.path.join(output_dir, 'model-weights-batch-n-4.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98755, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.98755 to 0.98910, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.98910\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98910 to 0.99066, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.99066 to 0.99144, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99144\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99144 to 0.99299, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99299\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99299\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99299\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.99299 to 0.99397, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99397\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.99397 to 0.99552, saving model to .tmp\\model-weights-batch-n-4.hdf5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99552\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.99552\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257a41ddcf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_0_batch_n_4.fit(X_train_0, y_train_0, \n",
    "                      epochs=100, \n",
    "                      verbose=0, \n",
    "                      validation_data=(X_test_0, y_test_0), \n",
    "                      callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning with 10 inner layers and 10 normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_6 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_7 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_8 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_9 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_10 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_11 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_12 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_13 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_14 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_15 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 184,005\n",
      "Trainable params: 182,005\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0_batch_n_10 = build_model_batch_n((28*28,), 5, n_layers=10)\n",
    "model_0_batch_n_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=os.path.join(output_dir, 'model-weights-batch-n-10.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98229, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.98229 to 0.98618, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.98618 to 0.99027, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.99027\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99027\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.99027 to 0.99144, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99144 to 0.99241, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99241\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99241\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99241\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99241\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99241\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.99241 to 0.99280, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99280\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99280\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.99280 to 0.99475, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99475\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.99475 to 0.99514, saving model to .tmp\\model-weights-batch-n-10.hdf5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.99514\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.99514\n",
      "Wall time: 3min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257ab5343c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_0_batch_n_10.fit(X_train_0, y_train_0, \n",
    "                       epochs=100, \n",
    "                       verbose=0, \n",
    "                       validation_data=(X_test_0, y_test_0), \n",
    "                       callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
